#summary All things Security - ASC

<wiki:toc max_depth="3" />

= Architecture Risk Analysis =

<tldr>
If you remember nothing else from these pages it should be this:
 * Who is attacking?
 * What are they attacking?
 * How they are attacking?
</tldr>

== Why Bother? ==
The techniques discussed below will help those involved in the design on software to:
 * Evaluate & prioritise threats & attacks
 * Build Trust & Threat Models for a software system
 * Analyse threats and attacks using Trust & Threat Models
 * Gain techniques for designing security controls

== When? ==
*When should we think about Architecture Risk Analysis?* The best time to think about security and risk analysis is during the early phases of requirements collection & design and then again when testing the code that implements that design, the list below outlines the usual phases of security related activity during the traditional software life-cycle:
 # Abuse Cases
 # Security Requirements
 # *Risk Analysis* (occurring during both the Requirements & Use Cases & Architecture & Design phases)
 # External Review
 # Risk-based Security Tests
 # Code Review (Tools)
 # *Risk Analysis* (occurring again during the Test & Test Results phase)
 # Penetration Testing
 # Security Operations

== What is a Secure Architecture? ==
There are two popular models:

=== CIA ===
This is quite a abstract model which means a lot in down to personal interpretation.
==== Confidentiality ====
Limiting access and disclosure to "the right people"; preventing access by or disclosure to "the wrong people".
==== Integrity ====
The trustworthiness of information resources.
==== Availability ====
Information systems provide access to authorized users.
=== Viega & !McGraw ===
Viega & !McGraw present a more granular definition:
 * Prevention
 * Traceability & Auditing
 * Monitoring
 * Privacy & Confidentiality
 * Multilevel Security
 * Anonymity
 * Authentication
 * Integrity

== Abuse & Misuse Cases ==
These are just like user cases although they deal exclusively with situations to designers or developers might not have envisioned the systems being used for when they first designed and implemented it. An example of a misuse case might be users injecting HTML code into their Facebook profile responses, they just want to make the profile stand out and have no malicious intent however the misuse case exposes a bug. You could easily turn this situation in to an abuse case by making the user a mis-actor who maliciously injects !JavaScript into the response block in an attempt to steal information from the computers of other users who visit their profile or take control of their accounts. 

== What constitutes an Insecure Design? ==
Both of the areas below contribute to insecure software, studies have shown that there is roughly a 50-50 split between the two categories.
=== Implementation Bugs ===

Broken code, for example:
 * Buffer overflow
  * String format
  * One-stage attacks
 * Race conditions
  * Time of check to time of use (TOCTOU)
  * Session & thread management
 * Unsafe environment variables
 * Unsafe system calls
  * System()
 * Untrusted input problems

=== Architecture Flaws ===

Design problems that create security vulnerabilities:
 * Misuse of cryptography
 * Duplicated data or code
 * Lack of consistent input validation
 * Missing authentication checks
 * Insecure or lack of auditing
 * Lack of authentication or session management on APIs
 * Missing compartmentalization (*storing secure information on the client side where a smart hacker might be able to manipulate it*)

== ARA Subprocesses ==

There are 3 discrete subprocesses which must be carried out during ARA:
 * Underlying Framework Weakness
  * Shows dependencies on toolkits and frameworks using within the application
  * How solid is the foundation?
  * How solid is the usage of the foundation?
  * Any know vulnerabilities in utilised version
  * What are the security controls like?
  * Does the framework require connectivity to any external parties?
  * Is it necessary to explicitly turn security in the platform on?
  * Framework Options:
   * Cryptography: JCA (Java Cryptography Architecture) provides signing, hashing, encryption and decryption - there's a mix of client and server side cryptography solutions although we should favour server side wherever possible because client side requires the key to be distributed to the client which is a trust issue.
   * Authentication & Authorization: JAAS (Java Authentication & Authorization Service) this is just a proxy essentially, it doesn't make any decisions itself, it merely delegates to something else to make those decisions. 
   * Input Validation & Output Encoding: .NET validateRequest (good for cross-site scripting) must be used with other forms of checks.
   * Sandboxing: !JavaScript (single origin policy) 
 * Attack Resistance Analysis
  * Apply checklist of known attacks
   * e.g. OWASP10
  * Risk-based judgement of fitness
 * Ambiguity Analysis
  * Find attacks based on how the system works
  * Expose invalid assumptions

=== Design Elements for Enterprise Applications ===

==== Common Design Elements for Enterprise Applications ====
 * Identify design elements that are historically vulnerable to attack
 * Enterprise applications share many of the same design elements
  * Distributed architecture
  * Dynamic code generation and interpretation
  * APIs across stateless protocols
  * Rich Internet Applications
  * Service-oriented Architecture

=== Enterprise Design Element: Distributed architecture ===
Networks are susceptible to:
 * Eavesdropping
 * Tampering
 * Spoofing
 * Hijacking
 * Observing 

We can reduce these into three common patterns:
 * Interposition attacks
 * Sniffing attacks
 * Replay attacks

=== Enterprise Design Element: Dynamic code generation and interpretation ===
 * Languages and programming environments are moving more decisions from design-time to run-time
 * Many attacks involve misinterpretation of data as code in these environments
 * When and how will user input be used by runtime language interpreters?
 * Relevant Attack Patterns
  * Cross-site Scripting (XSS)
  * SQL Injection
  * Buffer overflow
  * XML Injection
  * Shell command Injection
  * Cross-site Request Forgery (CSRF)
(The idea of a computer being able to interpret user data as code is known as the von Neumann curse.)

=== Enterprise Design Element: APIs across stateless protocols ===
 * Identifiers representing state can be abused
  * Prediction
  * Capture
  * Fixation
 * State sent to the client between requests is altered or replayed
 * Relevant Attack Patterns
  * Session hijacking/fixation
  * CSRF
  * Message replay
  * Parameter manipulation

=== Enterprise Design Element: Rich Internet Applications ===
 * Processing moves to the client-side
 * Relevant Attack Patterns
  * Direct API calls
  * CSRF
  * XSS
 * Unique Attacks
  * !JavaScript hijacking
  * Ajax interposition

=== !JavaScript Hijacking ===
 * !JavaScript Hijacking requires that the application return JSON objects
 * The attacker loads the attack script into the !JavaScript environment
 * The attacking page uses a `<SCRIPT>` tag to make the cross page reference

=== AJAX Interposition ===
This is basically where a hacker overrides the functions that run in your clients side by loading scripts from the hackers site.

*1. Modify the XMLHTTPREquest prototype*
{{{
var xmlreqc=XMLHTTPRequest;
XMLHTTPRequest = function() {
   this.XHR = new xmlreqc();
   return this;
}
}}}

*2. Wrap the send method*
{{{
XMLHttpRequest.prototype.send = function(content){
   //..add code to steal or alter content
   Sniff_and_Modify(content);
   //Pass call on
   return this.HNR.send(pay);
}
}}}

=== Enterprise Design Element: Service-oriented Architecture ===
 * Security need for SOA components
  * Web-services: SOAP/WSDL/UDDI
  * Message-oriented Middleware
  * Enterprise Service Bus
 * Common Problems
  * Exposing back-end code to dynamic attacks
  * Channel versus Message security
 * Relevant Attach Patterns:
  * XML Injecion / SQL Injection
  * Session Management Attacks
  * Direct File Manipulation

Specifically with XML a DOM parser is susceptible to a Denial of Service (DoS) attacks while SAX parsers are vulnerable to premature overriding of tags, i.e. the hacker inserts the end tag or something unrecognised to try and break parsing and cause an exception.

== Ambiguity Analysis ==
*Remember:* these are types of attacks that are specific to your system and how it is designed.

We can use different types of modelling to help us:
 # Trust Modelling - Identifies the boundaries of security policy for function and data.
 # Data Sensitivity Modelling - Identifies the privacy and trust issues for application data.
 # Threat Modelling - Identifies the function/data to protect; the person trying to attack; the vulnerability an attackers can exploit.

=== Trust Modelling ===
During trust modelling we attempt to identify different zones within the application and how information should flow between those zones. A good way to begin this analysis is by identifying subsystems within the application, when control flows between subsystems we might encounter a trust boundary, at which point the callee must establish its level of trust. Demarcation should also be made between subsystems holding different levels of sensitive information, each touch point between those components should be analysed to ensure leakage from one level to the next isn't occurring.

https://thesandbox.googlecode.com/svn/images/trust_zones.png

=== Data Sensitivity Modelling ===
 * What different classifications of data exist?
  * Security
  * Non-Security
 * Application data
  * Personal or Regulated data
  * Proprietary & Confidential data
 * Identify sensitive data:
  * At Rest - stores like the DBMS
  * In Transit - transfer via network, queues
  * In Use - in applications at runtime

These could include usernames, passwords, key stores etc. An example of this type of analysis might be social engineering via a telephone customer services number, a clever hacker might be able to ask questions is such way as to reveal what information the operator has on screen, e.g. a list of addresses or National Insurance numbers, if so it's safe to assume that all this information has leaked through the entire system, from the persistent back-end right up to the UI, where it sits on the terminal of the operator, this means the operator can see the whole NI number and does the verification themselves, we could significantly increase the security of the system by factoring the decision making login into a trust zone out of which the data never leaks, so instead of viewing the entire NI no. on screen the operator would be required to enter what the customer told them into a field and submit it to the trust zone which would verify the entry and return a boolean to indicate whether to proceed or not. By preventing the leak to the operator from our newly established trust zone we can reduce the chance or a social engineer extracting sensitive data from our system.

=== Threat Modelling ===
What is a threat? A threat is an actor/user who has malicious intent. Just like a normal user they have capabilities within the system, the threats' goal is usually to subvert security control in order to find a "loophole" in the system. *A threat isn't classified as just an unknown user of the system, when modelling threats you should also consider the support staff, developers and administrators too.* I guess you have to decide how much you implicitly trust those members of staff.

Formal definition: THREAT - a potential event that will have an unwelcome consequence. e.g. viewing sensitive data or elevating privilege. Ultimately a threat is a person or agent attempting to perform an unauthorized action.

==== Rules of Engagement ====

 * Capability
  * Access to the system
  * Able to reverse engineer binaries
  * Able to sniff the network
 * Motivation
  * Personal gain
  * Challenge / Ego
  * Competitive advantage
 * Skill Level
  * Experienced hacker
  * Script kiddie
  * Insiders (administrators)
 * Resources & Tools
  * Simple manual execution
  * Distributed bot army
  * Well-funded organisation
  * Access to internal information

A full threat model:

https://thesandbox.googlecode.com/svn-history/r337/images/threat_model.png

=== Application Assets ===
To help us model effectively we need to take time to understand what the assets of a application that we need to protect might be, these are things that would be of interest to an attacker and might include:
 * The applications functions - the application can perform some action that the threat would like to invoke
 * The applications sensitive data - this could be data stored in a database or even data leaked into log files
 * The application's state - data generated as the application run e.g. sequence numbers, session identifiers, encryption keys, access credentials/privileges etc.
 * Assets of the user and of the other systems the user uses - e.g. if we have a user who uses our application and uses internet backing then is it possible for our system to be exploited to allow a hacker to send code to the user browser allowing them to steal information when the user logs in to their bank?

== Principles of Secure Design ==
There are 9 guiding principles that help us achieve Secure Design

=== 1. Secure the Weakest Link ===
Securing your front door like Fort Knox is good but useless if you then leave your side window open! Software security != Secure software

==== What Goes Wrong ====
 * Obsess about the largest system of main functionality
  * Example: IIS vs. Internet Hearts
 * Forget that this application is part of a larger ecosystem
  * Getting lost in the details

=== 2. Practice Defence in Depth ===
Don't reply on just a single point of security failure, complement at every level but don't  duplicate or overlap, e.g. encrypting data you're about to send to a client over SSL is pointless as SSL will handle encryption for you anyway, your encryption just duplicates your effort.

 * Manage risk with multiple strategies
 * Locks work better if you have alarms on them
 * Adding motion sensors helps more
 * Redundant subsystems can be as secure of as the _strongest_ link

==== What Goes Wrong ====
 * Some organisation do acceptance testing for functionality, but they do not test for security
 * Most QA people can't do security testing without some expert guidance
  * A risk analysis must inform the testing process
 * Focus only on a security functionality
  * Don't think like a bad guy

=== 3. Be Reluctant to Trust ===
When analysing a system make sure you're clear on where the trust points are and how you can validate them:
 * Is that server hacked?
 * Why trust that COTS (Commercial Off-The Shelf) software?
 * Bad guys are more resourceful that you think
 * Don't mimic everyone else
  * Common protocols are often fundamentally flawed
 * Trust is transitive
  * Trusted programs should not invoke untrusted ones, especially indirectly!

==== What Goes Wrong ====
 * Servers trust client, even hackable ones
 * Protocols are broken
  * WEP (Wired Equivalent Privacy)
  * SSL (Secure Sockets Layer)
 * Some applications validate input only in the client
 * Some insiders become threats
  * Malicious intent, inadvertently 

=== 4. Remember that Hiding Secrets is Hard ===
 * "Security through obscurity" doesn't work
 * You often don't have much control over the final program environment
 * Secrets can often be inferred from behaviour
 * Reverse engineering is not hard

==== What Goes Wrong ====
 * Storing passwords in code
  * Inline SQL with db passwords in it
  * Plaintext configuration files
 * Temporary files leaking information
 * Developers thinking "binaries" are not readable

=== 5. Follow the Principle of Least Privilege ===
These are massive warning signs that should flag up major concerns, especially when an application uses the "root" or "dba" password when accessing resources for example.

 * Give out no more privilege than necessary
 * Extend privilege for shortest possible time
 * Minimize windows of vulnerability
 * Don't hand out the key to your office
 * Provide data on a "need to know" basis

==== What Goes Wrong ====
 * Development environments require full machine administrative privilege
 * Programs in production have too much privilege
  * Web applications use the database administrator login because developer had full admin

=== 6. Fail and Recover Securely ===
Don't skimp on error/exception handling - these areas are often where you spend most of you time when your software enters the maintenance phase, ideally we should include error handling with every use case so it's important to make error handling a first class citizen during the design and development phases or delivery.

 * "Default to insecure" is bad but prevalent
  * Backwards compatibility issues
  * Web services allowing service submission
 * Use *abuse cases* to drive additional requirements
  * How important is security to the business?

==== What Goes Wrong ====
 * We want to deliver the service and not break existing users
  * Choosing a toolkit of a lower version to create compatibility
  * Encrypted versions that fails to cleartext
 * Error messages that leak program structure and/or provide information is exception messages (stack traces)

=== 7. Compartmentalise ===
Small and self sufficient process which just deal with a very limited number of concerns are very beneficial to the overall system, helping to reduce risk (as components could be run in their own sandbox) and increase uptime because one component doesn't bring everything else down with it like a monolithic architecture might.

 * Limit attackers ability to do damage
 * Mimic real examples:
  * Chambers in submarines
  * Jail cells
  * Money in your wallet
 * Apply process protection, chroot()
 * Use different keys for different devices
 * ISAPI settings for IIS
  * In process
  * Out of process
  * Pooled

==== What Goes Wrong ====
 * Simple buffer overflows cause entire security systems to give up the ghost
 * One application in a shared environment exposes all applications in that environment

=== 8. Keep it Simple ===
 * Fewer links make the system easier to secure
 * Complex code tends to be more buggy
 * Users need simple UIs
 * Don't use technology for technologies sake
 * Provide "choke points" without back doors
 * Seemingly contradicts defence-in-depth guideline
  * "Don't put all your eggs in one basket" is different from making a rat's nest

==== What Goes Wrong ====
 * The cure is worse that the disease
  * 20 passwords that al l must be different and change bi-weekly
  * No real understanding of trust boundaries
 * Changes over time to your environment or requirements may wreak havoc on code organization

=== 9. Promote Privacy ===
 * Hackers launch attacks based on easily collected information
 * Do not give out more information that you must
  * Example: Logins often provide OS version info
 * not all parts of the business can share the same information

==== What Goes Wrong ====
 * Error messages sometimes give away way too much information
 * Malicious hackers use this information to further their attack
  * Error reporting is NOT a debugging tool
  * Use logging for that
 * Services that cross business units leak information that is sensitive to one unit, but not sensitive to another

----

= Links =

[http://arstechnica.com/security/2013/09/security-of-java-takes-a-dangerous-turn-for-the-worse-experts-say/ Java 7 exploits reverse engineered and used to hack Java 6]