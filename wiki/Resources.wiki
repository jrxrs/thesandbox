#summary A selection of useful resources for various Programming Languages.

<wiki:toc max_depth="2" />

= Java =

== P.I.E. - The Pillars of Object Orientation ==

=== Polymorphism ===

[http://en.wikipedia.org/wiki/Polymorphism_in_object-oriented_programming Wikipedia: Polymorphism]

  * Is the ability of methods to behave differently, based on the object calling it

=== Inheritance ===

[http://en.wikipedia.org/wiki/Inheritance_(computer_science) Wikipedia: Inheritance]

  * In simple words, Inheritance is way to define new a class, using classes which have already been defined

=== Encapsulation ===

[http://en.wikipedia.org/wiki/Encapsulation_(object-oriented_programming) Wikipedia: Encapsulation]

  * With Encapsulation you can hide (restrict access) to critical data members in your code , which improves security
  * Encapsualtion combines data and actions together (just like a capsule)

==== Data Abstraction ====

[http://wiki.answers.com/Q/What_is_data_abstraction_in_java Data Abstraction in Java]

  * Abstraction in the process of selecting important data sets for an Object in your software , and leaving out the insignificant ones.
  * Once you have modeled your object using Abstraction , the same set of data could be used in different applications.

== Autoboxing ==

Autoboxing is available as of Java 1.5.0 and introduces the automated handling of primitive Java type to their equivalent Wrapper class. [http://java.sun.com/j2se/1.5.0/docs/guide/language/autoboxing.html Java 1.5.0 Language Guilde]

== Imports & Performace ==

Did some research and it seems that conventional wisdom suggests that using imports with the wild card character, of the form:
{{{
import javax.swing.*;
}}}
does not impact runtime performance. There is however a valid case for specifying exactly the classes you wish to import as detailed in [http://www.javafaq.nu/java-article914.html this article].

== Mutable & Immutable Objects ==

[http://www.javaranch.com/journal/2003/04/immutable.htm Java Ranch - Mutable and Immutable Objects]

== Generics ==

[http://onjava.com/onjava/excerpt/javaian5_chap04/index1.html Writing Generic Types & Methods]

== Checked & Unchecked Exceptions ==

[http://tutorials.jenkov.com/java-exception-handling/checked-or-unchecked-exceptions.html Java Exception Handling - Checked or Unchecked Exceptions]

== Challenging Java Questions ==

[http://robaustin.wikidot.com/50-java-interview-questions Java Interview Questions]

== Threading & Lock Contention ==

[http://www.thinkingparallel.com/2007/07/31/10-ways-to-reduce-lock-contention-in-threaded-programs/ 10 Ways to Reduce Lock Contention in Threaded Programs]

= Java EE =

[http://docs.oracle.com/javaee/6/tutorial/doc/docinfo.html Jave EE 6 Tutorial]

= XML =

== SAX & DOM ==

SAX - Event Driven, stack based parsing, akin to shift-reduce mechanism employed by bottom-up parsers. [http://en.wikipedia.org/wiki/Simple_API_for_XML Wikipedia]

DOM - Tree Walking [http://en.wikipedia.org/wiki/Document_Object_Model Wikipedia]

[http://onjava.com/onjava/2002/06/26/xml.html SAX & DOM, the Basics]

[http://www.informit.com/library/library.aspx?b=STY_XML_21days Teach Yourself XML in 21 Days]

= Data Structures & Algorithms =

A good alternative from [http://en.wikipedia.org/ Wikipedia] articles on data structures and algorithms is http://www.algolist.net/ which provides examples in Java & C++ along with explanations and analysis.

[http://so-i-think-i-created-my-first-online-project.googlecode.com/files/Data%20Structures%20and%20Algorithms%20in%20Java%20Fourth%20Edition.pdf?bcsi_scan_4c5c01dba4894524=0&bcsi_scan_filename=Data%20Structures%20and%20Algorithms%20in%20Java%20Fourth%20Edition.pdf Data Structures & Algorithms in Java (4th Edition)]

== Trees ==

=== Depth ===
*Formal Definition:* Let _v_ be a node of a tree _T_. The depth of _v_ is the number of ancestors of _v_, excluding _v_ itself. If _v_ is the root, then the depth of _v_ is 0.
*Informal Definition:* How deep down the tree is the node you're concerned with?

=== Height ===
*Formal Definition:* The height of a node _v_ in a tree _T_ is defined recursively:<br><li>If _v_ is an external node, then the height of _v_ is 0
<br><li>Otherwise, the height of _v_ is one plus the maximum height of a child of _v_.<br>
*Informal Definition:* So basically how far is _v_ away from it's further descendant which is a leaf (external node). 

Adapted from [http://en.wikipedia.org/wiki/Red_black_tree Red-Black Tree]: Both Red-Black tree ([http://www.ece.uc.edu/~franco/C321/html/RedBlack/redblack.html demo]) and AVL trees ([http://www.strille.net/works/media_technology_projects/avl-tree_2001/ demo]) support O(log n) search, insertion, and removal. AVLs are more rigidly balanced than red–black trees, leading to slower insertion and removal but faster retrieval. This makes AVLs attractive for data structures that may be built once and loaded without reconstruction, such as language dictionaries (or program dictionaries, such as the opcodes of an assembler or interpreter).

2-4 Trees ([http://www.cs.unm.edu/~rlpm/499/ttft.html demo]) are fundamental to understanding red-black trees because the insertion and deletion operations on 2-4 trees are also equivalent to colour-flipping and rotations in red–black trees, despite this 2-4 trees are seldom used in practice. Try walking through the [http://en.wikipedia.org/wiki/2-4_tree#Example example] from wikipedia of a 2-3-4 tree insertion.

*Differentiating Red-Black Trees*

Although AVL trees and (2,4) trees have a number of nice properties, there are some dictionary applications for which they are not well suited. For instance, AVL trees may require many restructure operations (rotations) to be performed after a removal, and (2,4) trees may require many fusing or split operations to be performed after either an insertion or removal. The red-black tree data structure does not have these drawbacks, however, as it requires that only O(1) structural changes be made after an update in order to stay balanced.

== Sorting ==

There are lots of different types of sorting algorithms, only some are covered here. A comparison of the space complexity of many of these algorithms can be found [http://en.wikipedia.org/wiki/Timsort#Performance here].

=== Selection Sort - O(n^2^) ===
*Basic Idea*: Ascend the unsorted array until the find the smallest value in the list, swap that value with the value in the first spot, then search adjust the position you are attempting to fill and search again for the next smallest etc. continuing until you reach the end and everything is sorted.

Selection sort is sometimes useful for small data sets where memory is limited.
Worst Case Performance: O(n^2^)
Best Case Performance: O(n^2^)
Average Case Performance: O(n^2^)

=== Insertion Sort - O(n^2^) ===
*Basic Idea*: 

Generally speaking (and despite having same worst case complexity) an Insertion Sort is expected to perform better than a Selection Sort.

Worst Case Performance: O(n^2^) comparisons, swaps
Best Case Performance: O(n) comparisons, O(1) swaps
Average Case Performance: О(n^2^) comparisons, swaps

[http://en.wikipedia.org/wiki/Insertion_sort#Comparisons_to_other_sorting_algorithms Comparisons]

=== Bubble Sort - O(n^2^) ===
*Basic Idea*: Bubble sort works by repeatedly stepping through the list to be sorted, comparing each pair of adjacent items and swapping them if they are in the wrong order. The pass through the list is repeated until no swaps are needed, which indicates that the list is sorted.

Worst Case Performance: O(n^2^)
Best Case Performance: O(n)
Average Case Performance: O(n^2^)

=== Quick Sort - O(n log n) (although not guaranteed) ===
*Basic Idea*: Is similar to merge sort in that is it a divide and conquer algorithm. [http://opendatastructures.org/versions/edition-0.1e/ods-java/11_1_Comparison_Based_Sorti.html#SECTION001412000000000000000 link] The basic idea is to pick a pivot value and move elements around (by swapping them) so that they fall on the correct side of the pivot value.

As the the Java Arrays API http://docs.oracle.com/javase/6/docs/api/java/util/Arrays.html#sort(int[]) Java uses a tuned quicksort to perform it's sorting, the algorithm offers n*log(n) performance on many data sets that cause other quicksorts to degrade to quadratic performance. That sort I have seen it suggested elsewhere that it uses Merge Sort

Worst Case Performance: O(n^2^) - although in practice this is very rare behaviour.
Best Case Performance: O(n log n)
Average Case Performance: O(n log n)
NOTE: Quick Sorts space complexity is O(log n) where as Merge Sorts is O(n)

=== Merge Sort - O(n log n) (guaranteed) ===
*Basic Idea*: This is a classic divide and conquer algorithm. Recursively halve your array until each item is on its own, then scan the first two items placing them in the correct order, complete this process with the next two items until each single item has been ordered as a pair (ignore odds), then take the first two pairs of sorted lists and scan both to create a order list of 4 items, keep going until the list of back together.

Worst Case Performance: O(n log n)
Best Case Performance: O(n log n)
Average Case Performance: O(n log n)

=== Timsort - O(n log n) ===
*Basic Idea*: Timsort is a hybrid sorting algorithm, derived from merge sort and insertion sort, designed to perform well on many kinds of real-world data. The algorithm finds subsets of the data that are already ordered, and uses the subsets to sort the data more efficiently. This is done by merging an identified subset, called a run, with existing runs until certain criteria are fulfilled.

Although it originated as a search for the Python programming language, as of Java SE 7 Timsort will be used to Array in Java as well.

Worst Case Performance: O(n log n)
Best Case Performance: O(n)
Average Case Performance: O(n log n)

=== Hash Sort - O(n) ===
*Basic Idea*: Maintain an array of buckets of items which is at least 20-25% larger than your list of items (to reduce clashes) and perform the same calculation on each item to return a numerical representation  of that item such that you can index into the array with that.

== Searching ==
=== Linear Search - O(n) ===
*Basic Idea*: Just search through the list from the beginning until you find the item you're looking for. With a linear search it tends* not to make much difference if the list is sorted or not (although you could have a very clever sort designed to place the most frequently used items at the front of the list).

Worst Case Performance: n
Best Case Performance: 1
Average Case Performance: n/2

=== Binary Search - O(log n) ===
*Basic Idea*: Particularly applicable to the tree structures discussed above. The tree must already be sorted and balanced if you want to achieve O(log n) guaranteed, remember that this take time and power in the first place.

Worst Case Performance: O(log n)
Best Case Performance: 1
Average Case Performance: ~O(log n)

=== Hash Search - O(1) ===
*Basic Idea*: Index into the list using the hash code you calculate for your item, if there are clashes you might not achieve your constant time target however if you stick to only ever being ~75-80% full then you shouldn't be too far off.

Hashes are not very efficient in terms of space because by definition you need some empty slots.

= Complexity (Big O) =

[http://pages.cs.wisc.edu/~vernon/cs367/notes/3.COMPLEXITY.html Complexity & Big-O Notation]
[http://stackoverflow.com/questions/2307283/what-does-olog-n-mean-exactly Good Explanation of O(log n) from Stackoverflow]

= Maths =

[http://oakroadsystems.com/math/loglaws.htm Logarithms]

= The OSI Application Model =

The [http://en.wikipedia.org/wiki/OSI_model Open Systems Interconnection] (OSI) model is a model used standardise the functions of a communications system in terms of abstraction layers. Similar communication functions are grouped into logical layers. A layer serves the layer above it and is served by the layer below it.

The 7 layers from top (nearest the user) to bottom are:<br>
*Application*<br>
*Presentation*<br>
*Session*<br>
*Transport*<br>
*Network*<br>
*Data Link*<br>
*Physical*

Below the are describe from bottom to top...

== Physical ==
The *Physical Layer* describes the physical properties of the various communications media; as well as the electrical properties and interpreation of the exchanged signals.<br/>
Example: this layer defines the size of the Ethernet coaxial cable, the type of the BNC connector used, and the termination method. e.g. IEEE 802.11

== Data Link ==
The *Data Link Layer* describes the logical organisation of data bits transmitted on a particular medium.<br/>
Example: this layer defines the framing, addressing and checksumming of Ethernet packets. e.g. Point-to-Point Protocol (PPP)

== Network ==
The *Network Layer* describes how a series of exchanges over various data links can deliver data between any two modes in a network.<br>
Example: this layer defines the addressing and routing structure of the Internet. e.g. IP (v4/v6)

== Transport ==
The *Transport Layer* describes the quality and nature of the data delivery.<br>
Example: this layer defines if and how retransmissions will be used to ensure data delivery. e.g. TCP/UDP

== Session ==
The *Session Layer* describes the organisation of data sequences larger than the packets handled by lower layers.<br>
Example: the layer describes how request and reply packets are paired in a remote procedure call. e.g. TSL/SSL

== Presentation ==
The *Presentation Layer* describes the syntax of data being transferred. <br>
Example: this layer describes how floating point numbers can be exchanged between hosts with different math formats. e.g. MIME

== Application ==
The *Application Layer* describes how real work actually gets done.<br>
Example: this layer would implement file system operations. e.g. HTTP, DHCP, NFS